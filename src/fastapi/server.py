import os
import jwt
import uuid
import json
import asyncio
from datetime import datetime, timedelta, timezone
from typing import Optional, Dict, Any, List
from pathlib import Path
from fastapi import FastAPI, HTTPException, Depends, status, Request, Query
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from pydantic_settings import BaseSettings
from google.auth.transport import requests as google_requests
from google.oauth2 import id_token
import requests

# Add src to path for agent imports
import sys
from pathlib import Path

src_path = Path(__file__).parent.parent
if str(src_path) not in sys.path:
    sys.path.insert(0, str(src_path))

# Import storage after path is configured
from storage import gcs_storage

# Import ADK HTTP Client (simple HTTP calls to ADK API server)
try:
    from adk_client import ADKClient
    print("‚úÖ ADK HTTP Client imported successfully")
except ImportError as e:
    print(f"Warning: Could not import ADKClient: {e}")
    ADKClient = None

# Initialize ADK client (connects to ADK API server on localhost:8000)
adk_client = ADKClient() if ADKClient else None

# Note: We're using ADK HTTP client instead of local agent imports
# This makes HTTP calls to the ADK API server which hosts the agents
# No need to import InMemoryRunner or local agent modules anymore!

# Note: We don't need to import local notebook generators anymore
# We use NotebookGeneratorWithGCS which uses the ADK HTTP client

# Custom notebook generator that uploads to GCS
class NotebookGeneratorWithGCS:
    """Extended NotebookGenerator that uploads files to GCS as they are created."""

    def __init__(self, config_file: str, output_dir: str, notebook_id: str, progress_callback=None):
        # Initialize basic properties
        self.config_file = config_file
        self.output_dir = Path(output_dir)
        self.notebook_id = notebook_id
        self.progress_callback = progress_callback

        # Load config
        with open(config_file, 'r', encoding='utf-8') as f:
            self.config = json.load(f)

        print(f"üîß Initializing GCS service with bucket: {settings.gcs_bucket_name}, credentials: {settings.gcs_credentials_path}")
        self.gcs_service = gcs_storage.GCSStorageService(
            bucket_name=settings.gcs_bucket_name,
            credentials_path=settings.gcs_credentials_path
        )
        print("‚úÖ GCS service initialized successfully")

        # Use ADK HTTP client for agent communication
        self.adk_client = adk_client
        if self.adk_client and self.adk_client.is_available():
            print("‚úÖ Using ADK HTTP client for agent communication (http://localhost:8000)")
        else:
            print("‚ö†Ô∏è ADK API server not available - content will use placeholder text")
            print("   Start ADK server with: cd src/agents && adk api_server --port 8000")

        # Load templates
        self.templates = self._load_templates()

    def _update_progress(self, step: str, percentage: int):
        """Update progress via callback if provided."""
        if self.progress_callback:
            self.progress_callback(step, percentage)

    def _load_templates(self) -> Dict[str, str]:
        """Load markdown templates."""
        templates_dir = Path(__file__).parent.parent / "agents" / "study_notes_generator" / "templates"
        templates = {}

        # Default fallback templates
        templates['note'] = """# {title}

**Subject:** {subject}
**Topic:** {topic}
**Difficulty:** {difficulty}
**Last Updated:** {date}

## Overview

{overview}

## Key Concepts

{key_concepts}

## Detailed Explanation

{detailed_content}

## Examples

{examples}

## Practice Exercises

{exercises}

## Related Topics

{related_topics}

## Resources

{resources}

---

*Generated by Study Notes Generator*
"""

        templates['index'] = """# {title}

**Subject:** {subject}
**Description:** {description}
**Difficulty Level:** {difficulty}

## Learning Path

{learning_path}

## Topics Overview

{topics_overview}

## Progress Tracking

{progress_tracking}

## Navigation

{navigation}

---

*Generated by Study Notes Generator*
"""

        templates['progress'] = """# Learning Progress - {subject}

**Started:** {start_date}
**Last Updated:** {update_date}

## Overall Progress

- [ ] Introduction and Prerequisites
{topic_checkboxes}
- [ ] Final Review and Assessment

## Detailed Topic Progress

{topic_progress}

## Learning Goals

{learning_goals}

## Notes and Reflections

{reflections}

---

*Generated by Study Notes Generator*
"""

        # Try to load custom templates from files if they exist
        template_files = {
            'note': 'note_template.md',
            'index': 'index_template.md',
            'progress': 'progress_template.md'
        }

        for template_name, filename in template_files.items():
            template_file = templates_dir / filename
            if template_file.exists():
                try:
                    with open(template_file, 'r', encoding='utf-8') as f:
                        templates[template_name] = f.read()
                    print(f"‚úÖ Loaded custom {template_name} template")
                except Exception as e:
                    print(f"‚ö†Ô∏è  Failed to load {template_name} template: {e}")

        return templates

    async def generate_notebook(self):
        """Override to use loop agent pattern for iterative content generation."""
        config_dict = self.config if isinstance(self.config, dict) else {}
        
        print(f"üéØ Generating study notebook for: {config_dict.get('subject', 'Unknown')}")
        print(f"‚òÅÔ∏è All files will be uploaded directly to GCS")
        print(f"üì¶ GCS Bucket Path: users/{_notebooks[self.notebook_id]['user_id']}/notebooks/{self.notebook_id}")

        # Step 1: Analyze content structure
        print("üîç Analyzing content structure...")
        self._update_progress("Analyzing content structure", 45)
        content_structure = await self._analyze_content()

        # Step 2: Generate research content using loop agent
        print("üìö Generating research content with loop agent...")
        self._update_progress("Generating AI content with agents", 55)
        research_content = await self._generate_research_content_with_loop_agent(content_structure)

        # Step 3: Create organization structure
        print("üìÇ Creating folder organization...")
        self._update_progress("Creating folder structure", 70)
        folder_structure = await self._create_folder_structure(research_content)

        # Step 4: Generate all files and upload to GCS using loop agent
        print("üìù Generating markdown files and uploading to GCS with loop agent...")
        self._update_progress("Uploading files to GCS", 80)
        await self._generate_files_with_loop_agent_and_upload(folder_structure, research_content)

        # Step 5: Create progress tracking
        if config_dict.get('include_progress_tracking', True):
            print("üìä Creating progress tracking...")
            self._update_progress("Finalizing notebook", 95)
            await self._create_progress_tracking_and_upload(research_content)

        print("‚úÖ Notebook generation complete!")
        print(f"‚òÅÔ∏è All files uploaded to GCS bucket: {settings.gcs_bucket_name}")
        print(f"üìñ Access path: users/{_notebooks[self.notebook_id]['user_id']}/notebooks/{self.notebook_id}")

    async def _generate_files_and_upload(self, folder_structure: Dict[str, Any], research_content: Dict[str, Any]):
        """Generate all markdown files and upload directly to GCS (no local storage)."""
        # No local directory creation - everything goes directly to GCS
        print("‚òÅÔ∏è All files will be uploaded directly to GCS (no local storage)")
        
        root_dir = Path(self.output_dir)  # Keep for path calculations only

        # Generate main index file and upload
        await self._generate_main_index_and_upload(root_dir, research_content)

        # Generate topic files and upload
        for topic in research_content["topics"]:
            topic_folder = root_dir / topic["name"].lower().replace(" ", "_")
            # No mkdir - just use for path calculations

            # Generate topic index and upload
            await self._generate_topic_index_and_upload(topic_folder, topic)

            # Generate main topic file and upload
            await self._generate_topic_file_and_upload(topic_folder, topic)

            # Generate subtopic files and upload
            for subtopic in topic.get("subtopics", []):
                subtopic_folder = topic_folder / subtopic["name"].lower().replace(" ", "_")
                # No mkdir - just use for path calculations

                await self._generate_topic_file_and_upload(subtopic_folder, subtopic, is_subtopic=True, parent_topic=topic["name"])

    async def _generate_main_index_and_upload(self, root_dir: Path, research_content: Dict[str, Any]):
        """Generate the main index file and upload to GCS."""
        index_content = self._generate_main_index_content(root_dir, research_content)

        # Upload directly to GCS without saving locally
        await self._upload_file_to_gcs("README.md", index_content)
        print(f"  ‚úÖ Main index uploaded to GCS (no local file)")

    async def _generate_topic_index_and_upload(self, topic_folder: Path, topic: Dict[str, Any]):
        """Generate topic index file and upload to GCS."""
        index_content = self._generate_topic_index_content(topic_folder, topic)

        # Upload directly to GCS without saving locally
        relative_path = topic_folder.relative_to(self.output_dir) / "README.md"
        await self._upload_file_to_gcs(str(relative_path), index_content)
        print(f"  ‚úÖ Topic index uploaded to GCS (no local file)")

    async def _generate_topic_file_and_upload(self, folder: Path, topic: Dict[str, Any], is_subtopic: bool = False, parent_topic: str = ""):
        """Generate a topic markdown file and upload to GCS."""
        filename = f"{topic['name'].lower().replace(' ', '_')}.md"
        filepath = folder / filename

        file_content = self._generate_topic_file_content(folder, topic, is_subtopic, parent_topic)

        # Upload directly to GCS without saving locally
        relative_path = filepath.relative_to(self.output_dir)
        await self._upload_file_to_gcs(str(relative_path), file_content)
        print(f"  ‚úÖ {topic['name']} uploaded to GCS (no local file)")

    async def _create_progress_tracking_and_upload(self, research_content: Dict[str, Any]):
        """Create progress tracking file and upload to GCS."""
        progress_content = self._generate_progress_content(research_content)

        # Upload directly to GCS without saving locally
        await self._upload_file_to_gcs("PROGRESS.md", progress_content)
        print(f"  ‚úÖ Progress tracking uploaded to GCS (no local file)")

    async def _upload_file_to_gcs(self, file_path: str, content: str):
        """Upload a file to GCS."""
        try:
            print(f"üì§ Attempting to upload {file_path} to GCS...")
            user_id = _notebooks[self.notebook_id]["user_id"]
            print(f"üë§ User ID: {user_id}, Notebook ID: {self.notebook_id}")
            result = self.gcs_service.upload_file(user_id, self.notebook_id, file_path, content)
            print(f"‚úÖ Successfully uploaded {file_path} to GCS: {result}")
        except Exception as e:
            print(f"‚ùå Failed to upload {file_path} to GCS: {e}")
            import traceback
            traceback.print_exc()
            # Continue processing - don't fail the entire generation

    def _generate_main_index_content(self, root_dir: Path, research_content: Dict[str, Any]) -> str:
        """Generate main index content (extracted from original method)."""
        topics_overview = ""
        learning_path = ""
        navigation = ""

        for i, topic in enumerate(research_content["topics"], 1):
            topic_folder = topic["name"].lower().replace(" ", "_")
            topics_overview += f"### {i}. {topic['name']}\n\n"
            topics_overview += f"{topic['description']}\n\n"
            topics_overview += f"üìÅ [Explore Topic]({topic_folder}/)\n\n"

            learning_path += f"{i}. [ ] {topic['name']} ({topic.get('estimated_time', '2 hours')})\n"

            navigation += f"- [{topic['name']}]({topic_folder}/)\n"

        progress_tracking = "## Progress Tracking\n\n" + learning_path

        # Calculate some basic stats
        total_time = "TBD"
        try:
            # Simple calculation based on topic time estimates
            time_parts = []
            for topic in research_content["topics"]:
                time_str = topic.get("estimated_time", "2 hours")
                if "hour" in time_str:
                    hours = int(time_str.split()[0])
                    time_parts.append(hours)
            if time_parts:
                total_hours = sum(time_parts)
                total_time = f"{total_hours} hours"
        except:
            total_time = "TBD"

        # Get first few topics for navigation examples
        first_topic = research_content["topics"][0] if research_content["topics"] else {"name": "topic1"}
        second_topic = research_content["topics"][1] if len(research_content["topics"]) > 1 else {"name": "topic2"}

        config_dict = self.config if isinstance(self.config, dict) else {}

        index_content = self.templates["index"].format(
            title=f"{config_dict.get('subject', 'Study Guide')} - Study Guide",
            subject=config_dict.get('subject', 'Unknown Subject'),
            description=config_dict.get('description', ''),
            difficulty=config_dict.get('difficulty', 'intermediate'),
            date=datetime.now().strftime("%Y-%m-%d"),
            learning_goals="Master all concepts and complete practical exercises",
            estimated_total_time=total_time,
            prerequisites=", ".join(config_dict.get('prerequisites', [])) if config_dict.get('prerequisites') else "None required",
            learning_path=learning_path,
            topics_overview=topics_overview,
            progress_tracking=progress_tracking,
            first_topic_folder=first_topic["name"].lower().replace(" ", "_"),
            first_topic=first_topic["name"].lower().replace(" ", "_"),
            second_topic_folder=second_topic["name"].lower().replace(" ", "_"),
            second_topic=second_topic["name"].lower().replace(" ", "_"),
            navigation=navigation,
            support_resources="Additional support resources will be listed here...",
            community_resources="Online communities and forums for discussion...",
            continuous_learning="Advanced topics and further study recommendations...",
            advanced_topics="Advanced topics will be suggested based on your progress..."
        )

        return index_content

    def _generate_topic_index_content(self, topic_folder: Path, topic: Dict[str, Any]) -> str:
        """Generate topic index content (extracted from original method)."""
        subtopics = topic.get("subtopics", [])
        navigation = f"- [‚Üê Back to Main](../README.md)\n"

        for subtopic in subtopics:
            subtopic_file = subtopic["name"].lower().replace(" ", "_")
            navigation += f"- [{subtopic['name']}]({subtopic_file}/)\n"

        # Simple topic index
        index_content = f"""# {topic['name']}

**Topic Overview**

{topic['description']}

## Files in this topic

- [{topic['name']}]({topic['name'].lower().replace(' ', '_')}.md) - Main topic content

## Navigation

{navigation}

---

*Generated by Study Notes Generator*
"""
        return index_content

    def _generate_topic_file_content(self, folder: Path, topic: Dict[str, Any], is_subtopic: bool = False, parent_topic: str = "") -> str:
        """Generate topic file content (extracted from original method)."""
        filename = f"{topic['name'].lower().replace(' ', '_')}.md"

        # Get parsed content sections (now a dict instead of string)
        content_sections = topic.get("content", {})
        if isinstance(content_sections, str):
            # Fallback for old format - create a dict with the string as detailed_content
            content_sections = {
                "learning_objectives": "Learning objectives will be detailed here...",
                "key_concepts": "Key concepts will be listed here...",
                "detailed_content": content_sections,
                "core_principles": "Core principles will be explained here...",
                "common_patterns": "Common patterns will be covered here...",
                "important_notes": "Important notes will be added here...",
                "examples": "Examples will be provided here...",
                "practical_applications": "Practical applications will be discussed here...",
                "exercises": "Practice exercises will be added here...",
                "beginner_exercises": "Beginner exercises will be listed here...",
                "intermediate_exercises": "Intermediate exercises will be listed here...",
                "advanced_challenges": "Advanced challenges will be listed here...",
                "related_topics": f"Related: {parent_topic}" if parent_topic else "See main index for related topics",
                "prerequisites": "Prerequisites will be listed here...",
                "next_steps": "Next steps will be suggested here...",
                "cross_references": "Cross-references will be added here...",
                "resources": "Additional resources will be listed here...",
                "recommended_reading": "Recommended reading will be listed here...",
                "online_resources": "Online resources will be listed here...",
                "tools": "Tools and software will be suggested here...",
                "study_notes": "Add your personal notes here..."
            }

        # Create navigation
        if is_subtopic:
            navigation = f"- [‚Üê Back to {parent_topic}](../README.md)\n- [‚Üê Back to Main](../../../README.md)"
        else:
            navigation = "- [‚Üê Back to Main](../README.md)"

        # Generate file content using template with parsed sections
        config_dict = self.config if isinstance(self.config, dict) else {}
        
        file_content = self.templates["note"].format(
            title=topic["name"],
            subject=config_dict.get('subject', 'Unknown Subject'),
            topic=topic["name"],
            difficulty=topic.get("difficulty", "intermediate"),
            date=datetime.now().strftime("%Y-%m-%d"),
            estimated_time=topic.get("estimated_time", "2 hours"),
            overview=topic.get("description", ""),
            learning_objectives=content_sections.get("learning_objectives", "Learning objectives will be detailed here..."),
            key_concepts=content_sections.get("key_concepts", "Key concepts will be listed here..."),
            detailed_content=content_sections.get("detailed_content", "Content generation in progress..."),
            core_principles=content_sections.get("core_principles", "Core principles will be explained here..."),
            common_patterns=content_sections.get("common_patterns", "Common patterns will be covered here..."),
            important_notes=content_sections.get("important_notes", "Important notes will be added here..."),
            examples=content_sections.get("examples", "Examples will be provided here..."),
            practical_applications=content_sections.get("practical_applications", "Practical applications will be discussed here..."),
            code_examples=content_sections.get("code_examples", "Code examples will be provided here..." if "python" in config_dict.get('subject', '').lower() else "Examples will be provided here..."),
            exercises=content_sections.get("exercises", "Practice exercises will be added here..."),
            beginner_exercises=content_sections.get("beginner_exercises", "Beginner exercises will be listed here..."),
            intermediate_exercises=content_sections.get("intermediate_exercises", "Intermediate exercises will be listed here..."),
            advanced_challenges=content_sections.get("advanced_challenges", "Advanced challenges will be listed here..."),
            related_topics=content_sections.get("related_topics", f"Related: {parent_topic}" if parent_topic else "See main index for related topics"),
            prerequisites=content_sections.get("prerequisites", "Prerequisites will be listed here..."),
            next_steps=content_sections.get("next_steps", "Next steps will be suggested here..."),
            cross_references=content_sections.get("cross_references", "Cross-references will be added here..."),
            resources=content_sections.get("resources", "Additional resources will be listed here..."),
            recommended_reading=content_sections.get("recommended_reading", "Recommended reading will be listed here..."),
            online_resources=content_sections.get("online_resources", "Online resources will be listed here..."),
            tools=content_sections.get("tools", "Tools and software will be suggested here..."),
            study_notes=content_sections.get("study_notes", "Add your personal notes here..."),
            navigation=navigation
        )

        return file_content

    def _generate_progress_content(self, research_content: Dict[str, Any]) -> str:
        """Generate progress tracking content (extracted from original method)."""
        topic_checkboxes = ""
        topic_progress = ""

        for topic in research_content["topics"]:
            topic_checkboxes += f"- [ ] {topic['name']}\n"

            topic_progress += f"### {topic['name']}\n\n"
            topic_progress += f"**Status:** Not started\n"
            topic_progress += f"**Estimated Time:** {topic.get('estimated_time', '2 hours')}\n"
            topic_progress += f"**Difficulty:** {topic.get('difficulty', 'intermediate')}\n\n"

            # Add subtopics
            for subtopic in topic.get("subtopics", []):
                topic_progress += f"- [ ] {subtopic['name']}\n"

            topic_progress += "\n"

        config_dict = self.config if isinstance(self.config, dict) else {}

        progress_content = self.templates["progress"].format(
            subject=config_dict.get('subject', 'Unknown Subject'),
            start_date=datetime.now().strftime("%Y-%m-%d"),
            update_date=datetime.now().strftime("%Y-%m-%d"),
            target_completion=(datetime.now().replace(day=1, month=datetime.now().month + 1) - datetime.now().replace(day=1)).days,
            overall_progress="0%",
            completed_topics="0",
            total_topics=str(len(research_content["topics"])),
            study_streak="0",
            time_remaining="TBD",
            progress_bar="‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë",
            total_study_time="0 hours",
            avg_session_time="0 minutes",
            productive_day="TBD",
            topic_checkboxes=topic_checkboxes,
            topic_progress=topic_progress,
            weekly_goals="Complete 2-3 topics this week",
            daily_log="Daily study log will be maintained here...",
            completed_topics_list="No topics completed yet",
            key_takeaways="Key takeaways will be added here...",
            effective_techniques="Effective techniques will be noted here...",
            improvement_areas="Areas for improvement will be identified here...",
            motivation_reflections="Motivation reflections will be added here...",
            short_term_goals="Complete first topic",
            medium_term_goals="Complete half of all topics",
            long_term_goals="Master all concepts and complete final project",
            resource_usage="Resource usage will be tracked here...",
            helpful_resources="Helpful resources will be listed here...",
            additional_resources="Additional resources to explore...",
            achievements="Achievements will be listed here...",
            recent_milestones="Recent milestones will be added here...",
            upcoming_milestones="Upcoming milestones will be planned here...",
            personal_notes="Add your personal notes and reflections here..."
        )

        return progress_content

    async def _generate_research_content_with_loop_agent(self, content_structure: Dict[str, Any]) -> Dict[str, Any]:
        """Generate detailed research content for each topic using loop agent pattern."""
        research_content = {
            "subject": content_structure["subject"],
            "topics": []
        }

        total_topics = len(content_structure["topics"])
        print(f"üìä Will generate content for {total_topics} main topics")

        # Use loop agent to coordinate content generation
        for i, topic in enumerate(content_structure["topics"]):
            print(f"\n{'='*60}")
            print(f"  üîÑ Processing topic {i+1}/{total_topics}: {topic['name']}")
            print(f"{'='*60}")

            # Generate content for main topic using loop agent
            topic_content = await self._generate_topic_content_with_loop_agent(topic, research_content["topics"])
            topic_content["subtopics"] = []

            # Generate content for subtopics
            num_subtopics = len(topic.get("subtopics", []))
            if num_subtopics > 0:
                print(f"  üìë Topic has {num_subtopics} subtopics")
            
            for j, subtopic in enumerate(topic.get("subtopics", [])):
                print(f"    üî∏ Subtopic {j+1}/{num_subtopics}: {subtopic['name']}")
                subtopic_data = {
                    "name": subtopic["name"],
                    "description": subtopic.get("description", ""),
                    "parent_topic": topic["name"],
                    "difficulty": subtopic.get("difficulty", topic["difficulty"]),
                    "key_concepts": subtopic.get("key_concepts", []),
                    "estimated_time": subtopic.get("estimated_time", "1-2 hours"),
                    "learning_objectives": subtopic.get("learning_objectives", []),
                    "prerequisites": subtopic.get("prerequisites", []),
                    "resources": subtopic.get("resources", [])
                }
                subtopic_content = await self._generate_topic_content_with_loop_agent(subtopic_data, topic_content["subtopics"])
                topic_content["subtopics"].append(subtopic_content)

            research_content["topics"].append(topic_content)
            print(f"  ‚úÖ Completed topic {i+1}/{total_topics}: {topic['name']}")

        print(f"\n‚úÖ All {total_topics} topics generated!")
        return research_content

    async def _generate_topic_content_with_loop_agent(self, topic: Dict[str, Any], previous_topics: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Generate content for a specific topic using loop agent with context awareness."""
        is_subtopic = 'parent_topic' in topic and topic['parent_topic'] != 'N/A'

        # Convert config to dict for easier access
        config_dict = self.config if isinstance(self.config, dict) else {}

        # Adjust content depth for subtopics (more focused)
        content_depth = "focused" if is_subtopic else config_dict.get("content_depth", "intermediate")

        # Build context from previous topics for cross-references
        context_summary = ""
        if previous_topics:
            context_summary = "Previous topics covered:\n" + "\n".join([
                f"- {t['name']}: {t.get('description', '')[:100]}..."
                for t in previous_topics[-3:]  # Last 3 topics for context
            ])

        # Loop agent prompt for iterative content generation
        if is_subtopic:
            loop_prompt = f"""
            Generate focused study notes for the following SUBTOPIC using structured markdown format.
            This is part of an iterative notebook generation process.

            Subject: {config_dict.get('subject', 'Unknown')}
            Parent Topic: {topic['parent_topic']}
            Subtopic: {topic['name']}
            Description: {topic.get('description', 'N/A')}
            Difficulty Level: {topic.get('difficulty', 'intermediate')}
            Content Depth: {content_depth}

            Key Concepts to Cover: {', '.join(topic.get('key_concepts', []))}

            Context from Previous Content:
            {context_summary}

            IMPORTANT: This is iteration {len(previous_topics) + 1} in the notebook generation loop.
            Ensure this subtopic content complements the parent topic "{topic['parent_topic']}"
            and builds upon previously generated content without unnecessary repetition.

            Generate content in the following EXACT markdown structure:

            ## Learning Objectives
            [Specific learning objectives for this subtopic]

            ## Key Concepts
            [List key concepts specific to this subtopic]

            ## Detailed Explanation
            [Focused content specific to this subtopic]

            ## Core Principles
            [Principles specific to this subtopic]

            ## Common Patterns
            [Patterns relevant to this subtopic]

            ## Important Notes
            [Critical information specific to this subtopic]

            ## Examples
            [Practical examples for this subtopic]

            ## Practical Applications
            [Applications specific to this subtopic]

            ## Practice Exercises
            [Exercises focused on this subtopic]

            ## Beginner Exercises
            [Simple exercises for this subtopic]

            ## Intermediate Exercises
            [Moderate exercises for this subtopic]

            ## Advanced Challenges
            [Challenging exercises for this subtopic]

            ## Related Topics
            [How this subtopic connects to other topics in the notebook]

            ## Prerequisites
            [What you need to know before this subtopic]

            ## Next Steps
            [What to learn next in this topic area]

            Focus on depth rather than breadth. Build upon the iterative generation process.
            """
        else:
            # Main topic prompt
            loop_prompt = f"""
            Generate comprehensive study notes for the following MAIN TOPIC using structured markdown format.
            This is iteration {len(previous_topics) + 1} in the notebook generation loop.

            Subject: {config_dict.get('subject', 'Unknown')}
            Topic: {topic['name']}
            Description: {topic.get('description', 'N/A')}
            Difficulty Level: {topic.get('difficulty', 'intermediate')}
            Content Depth: {config_dict.get('content_depth', 'intermediate')}
            Category: {config_dict.get('subject', 'Unknown')}

            Key Concepts to Cover: {', '.join(topic.get('key_concepts', []))}
            Estimated Time: {topic.get('estimated_time', '2-4 hours')}

            Context from Previously Generated Topics:
            {context_summary}

            Generate content in the following EXACT markdown structure:

            ## Learning Objectives
            [Specific, measurable learning objectives for this topic]

            ## Key Concepts
            [List key concepts and definitions]

            ## Detailed Explanation
            [Main content and explanations]

            ## Core Principles
            [Fundamental principles and theories]

            ## Common Patterns
            [Common patterns, techniques, and approaches]

            ## Important Notes
            [Critical information, tips, and warnings]

            ## Examples
            [Practical examples and illustrations]

            ## Practical Applications
            [Real-world applications and use cases]

            ## Practice Exercises
            [Hands-on exercises and problems]

            ## Beginner Exercises
            [Simple exercises for beginners]

            ## Intermediate Exercises
            [Moderate difficulty exercises]

            ## Advanced Challenges
            [Complex, challenging exercises]

            ## Related Topics
            [Connections to previously generated and upcoming topics]

            ## Prerequisites
            [Required knowledge before this topic]

            ## Next Steps
            [What to learn after this topic]

            Make the content educational, comprehensive, and suitable for deep learning.
            Ensure this topic builds logically upon the previous topics in the generation sequence.
            """

        # Use ADK HTTP client for content generation
        print(f"ü§ñ Generating content for topic: {topic['name']}")
        
        response_text = None
        
        if self.adk_client and self.adk_client.is_available():
            try:
                # Get user_id from notebook metadata
                user_id = _notebooks.get(self.notebook_id, {}).get("user_id", "anonymous")
                
                # Generate random session ID for this topic
                session_id = self.adk_client.generate_session_id(user_id)
                print(f"  üìå Session: {session_id} for user: {user_id}")
                
                # Call content generator via ADK HTTP API
                response_text = self.adk_client.generate_content_simple(
                    app_name="content_generator",
                    user_id=user_id,
                    message=loop_prompt,
                    initial_state={
                        "topic": topic['name'],
                        "subject": config_dict.get('subject', 'Unknown'),
                        "difficulty": topic.get('difficulty', 'intermediate')
                    }
                )
                print(f"  ‚úÖ Received {len(response_text)} chars from ADK agent")
            except Exception as e:
                print(f"  ‚ùå Error calling ADK server: {e}")
                print(f"  ‚ö†Ô∏è Falling back to placeholder content")
                response_text = None
        
        if not response_text:
            # Fallback to placeholder
            print(f"  ‚ö†Ô∏è ADK server not available, using placeholder content")
            response_text = f"""
## Learning Objectives
- Understand {topic['name']}
- Apply concepts in practical scenarios

## Key Concepts
{topic['name']} is a fundamental concept in {config_dict.get('subject', 'this subject')}.

## Detailed Explanation
This is placeholder content for {topic['name']}. To get AI-generated content:
1. Start ADK server: cd src/agents && adk api_server --port 8000
2. Ensure GOOGLE_APPLICATION_CREDENTIALS is set
3. Re-generate the notebook

## Examples
Example content will be generated when the ADK server is running.

## Practice Exercises
1. Review the key concepts
2. Try implementing examples
3. Complete the challenges

## Related Topics
- Related concepts in {config_dict.get('subject', 'this subject')}
"""

        # Parse the structured response into sections
        parsed_sections = self._parse_structured_response(response_text)

        return {
            "name": topic["name"],
            "description": topic.get("description", ""),
            "content": parsed_sections,
            "difficulty": topic.get("difficulty", "intermediate"),
            "estimated_time": topic.get("estimated_time", "2 hours")
        }

    async def _analyze_content(self) -> Dict[str, Any]:
        """Analyze and structure the notebook content based on config."""
        config_dict = self.config if isinstance(self.config, dict) else {}
        
        subject = config_dict.get("subject", "Unknown Subject")
        topics_list = config_dict.get("topics", [])
        
        # If no topics provided, create a default structure
        if not topics_list:
            topics_list = [{
                "name": "Introduction",
                "description": f"Introduction to {subject}",
                "difficulty": config_dict.get("difficulty", "beginner"),
                "estimated_time": "2 hours",
                "key_concepts": [],
                "learning_objectives": [],
                "prerequisites": [],
                "subtopics": []
            }]
        
        content_structure = {
            "subject": subject,
            "difficulty": config_dict.get("difficulty", "intermediate"),
            "topics": topics_list
        }
        
        return content_structure

    async def _create_folder_structure(self, research_content: Dict[str, Any]) -> Dict[str, Any]:
        """Create the folder structure for the notebook."""
        folder_structure = {
            "root": self.output_dir,
            "topics": []
        }
        
        for topic in research_content["topics"]:
            topic_folder = {
                "name": topic["name"],
                "path": self.output_dir / topic["name"].lower().replace(" ", "_"),
                "subtopics": []
            }
            
            for subtopic in topic.get("subtopics", []):
                subtopic_folder = {
                    "name": subtopic["name"],
                    "path": topic_folder["path"] / subtopic["name"].lower().replace(" ", "_")
                }
                topic_folder["subtopics"].append(subtopic_folder)
            
            folder_structure["topics"].append(topic_folder)
        
        return folder_structure

    def _parse_structured_response(self, response_text: str) -> Dict[str, Any]:
        """Parse the agent's structured markdown response into sections."""
        sections = {
            "learning_objectives": "",
            "key_concepts": "",
            "detailed_content": "",
            "core_principles": "",
            "common_patterns": "",
            "important_notes": "",
            "examples": "",
            "practical_applications": "",
            "exercises": "",
            "beginner_exercises": "",
            "intermediate_exercises": "",
            "advanced_challenges": "",
            "related_topics": "",
            "prerequisites": "",
            "next_steps": "",
            "cross_references": "",
            "resources": "",
            "recommended_reading": "",
            "online_resources": "",
            "tools": "",
            "study_notes": "",
        }
        
        # Simple parsing: split by ## headers
        lines = response_text.split('\n')
        current_section = None
        current_content = []
        
        section_mapping = {
            "learning objectives": "learning_objectives",
            "key concepts": "key_concepts",
            "detailed explanation": "detailed_content",
            "core principles": "core_principles",
            "common patterns": "common_patterns",
            "important notes": "important_notes",
            "examples": "examples",
            "practical applications": "practical_applications",
            "practice exercises": "exercises",
            "beginner exercises": "beginner_exercises",
            "intermediate exercises": "intermediate_exercises",
            "advanced challenges": "advanced_challenges",
            "related topics": "related_topics",
            "prerequisites": "prerequisites",
            "next steps": "next_steps",
            "cross references": "cross_references",
            "resources": "resources",
            "recommended reading": "recommended_reading",
            "online resources": "online_resources",
            "tools": "tools",
            "study notes": "study_notes",
        }
        
        for line in lines:
            if line.strip().startswith('##'):
                # Save previous section
                if current_section and current_content:
                    sections[current_section] = '\n'.join(current_content).strip()
                
                # Start new section
                header = line.strip().lstrip('#').strip().lower()
                current_section = section_mapping.get(header)
                current_content = []
            elif current_section:
                current_content.append(line)
        
        # Save last section
        if current_section and current_content:
            sections[current_section] = '\n'.join(current_content).strip()
        
        # If no sections were parsed, put everything in detailed_content
        if all(not v for v in sections.values()):
            sections["detailed_content"] = response_text
        
        return sections

    async def _generate_files_with_loop_agent_and_upload(self, folder_structure: Dict[str, Any], research_content: Dict[str, Any]):
        """Generate all markdown files using loop agent pattern and upload to GCS."""
        # No local directory creation - everything goes directly to GCS
        print("‚òÅÔ∏è All files will be uploaded directly to GCS (no local storage)")
        
        root_dir = Path(self.output_dir)  # Keep for path calculations only

        # Generate main index file and upload
        await self._generate_main_index_and_upload(root_dir, research_content)

        # Loop through topics and generate files iteratively
        for topic in research_content["topics"]:
            topic_folder = root_dir / topic["name"].lower().replace(" ", "_")
            # No mkdir - just use for path calculations

            # Generate topic index and upload
            await self._generate_topic_index_and_upload(topic_folder, topic)

            # Generate main topic file and upload
            await self._generate_topic_file_and_upload(topic_folder, topic)

            # Generate subtopic files and upload
            for subtopic in topic.get("subtopics", []):
                subtopic_folder = topic_folder / subtopic["name"].lower().replace(" ", "_")
                # No mkdir - just use for path calculations

                await self._generate_topic_file_and_upload(subtopic_folder, subtopic, is_subtopic=True, parent_topic=topic["name"])


class Settings(BaseSettings):
    """Application settings with environment variable support."""
    
    # JWT Settings
    jwt_secret_key: str = Field(default="your-secret-key-change-in-production", env="JWT_SECRET_KEY")
    jwt_algorithm: str = Field(default="HS256", env="JWT_ALGORITHM")
    jwt_expiration_hours: int = Field(default=24, env="JWT_EXPIRATION_HOURS")
    
    # Google OAuth Settings
    google_client_id: str = Field(default="", env="GOOGLE_CLIENT_ID")
    google_client_secret: str = Field(default="", env="GOOGLE_CLIENT_SECRET")
    
    # Google API Settings
    google_api_key: str = Field(default="", env="GOOGLE_API_KEY")
    google_genai_use_vertexai: str = Field(default="0", env="GOOGLE_GENAI_USE_VERTEXAI")
    
    # GCP Settings
    gcp_project_id: str = Field(default="learnpad-gcp", env="GCP_PROJECT_ID")
    google_application_credentials: str = Field(default="", env="GOOGLE_APPLICATION_CREDENTIALS")

    # GCS Settings
    gcs_project_id: str = Field(default="learnpad-gcp", env="GCS_PROJECT_ID")
    gcs_bucket_name: str = Field(default="learnpad-gcp-dev", env="GCS_BUCKET_NAME")
    gcs_credentials_path: str = Field(default="learnpad-backend-key.json", env="GCS_CREDENTIALS_PATH")
    gcs_base_path: str = Field(default="users", env="GCS_BASE_PATH")
    
    # Vertex AI / Agent Settings (legacy, kept for .env compatibility)
    notebook_engine_id: str = Field(default="", env="NOTEBOOK_ENGINE_ID")
    agent_app_name: str = Field(default="learnpad_orchestrator", env="AGENT_APP_NAME")
    google_cloud_project: str = Field(default="", env="GOOGLE_CLOUD_PROJECT")
    google_cloud_location: str = Field(default="us-central1", env="GOOGLE_CLOUD_LOCATION")
    
    # API Settings
    backend_url: str = Field(default="http://localhost:8001", env="BACKEND_URL")
    
    # CORS Settings
    cors_origins: list[str] = Field(default=["http://localhost:3000", "http://localhost:8001"], env="CORS_ORIGINS")
    
    # Notebook Settings
    notebooks_base_path: str = Field(default="./notebooks", env="NOTEBOOKS_BASE_PATH")
    assessment_session_ttl_hours: int = Field(default=24, env="ASSESSMENT_SESSION_TTL_HOURS")
    
    class Config:
        env_file = ".env"


# Initialize settings
settings = Settings()

# Initialize FastAPI app
app = FastAPI(
    title="LearnPad API",
    description="Authentication-enabled API for LearnPad application",
    version="1.0.0"
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.cors_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Security
security = HTTPBearer()


# Pydantic models
class GoogleTokenRequest(BaseModel):
    """Request model for Google token verification."""
    token: str = Field(..., description="Google ID token")


class LoginResponse(BaseModel):
    """Response model for successful login."""
    access_token: str = Field(..., description="JWT access token")
    token_type: str = Field(default="bearer", description="Token type")
    expires_in: int = Field(..., description="Token expiration time in seconds")
    user_info: Dict[str, Any] = Field(..., description="User information")


class UserInfo(BaseModel):
    """User information model."""
    sub: str = Field(..., description="User ID")
    email: str = Field(..., description="User email")
    name: str = Field(..., description="User full name")
    picture: Optional[str] = Field(None, description="User profile picture URL")
    email_verified: bool = Field(default=False, description="Email verification status")


class TokenData(BaseModel):
    """Token payload data."""
    sub: str
    email: str
    name: str
    picture: Optional[str] = None
    exp: datetime
    iat: datetime


# Notebook API Pydantic Models

# User Assessment Models
class AssessmentStartRequest(BaseModel):
    """Request to start assessment session."""
    subject: Optional[str] = Field(None, description="Subject/topic of interest")
    initial_goals: Optional[str] = Field(None, description="Initial learning goals")
    user_id: str = Field(..., description="User ID")


class AssessmentMessageRequest(BaseModel):
    """Request to send message in assessment session."""
    message: str = Field(..., description="User message")
    user_id: str = Field(..., description="User ID")


class AssessmentStartResponse(BaseModel):
    """Response for starting assessment session."""
    session_id: str = Field(..., description="Assessment session ID")
    status: str = Field(..., description="Session status")
    initial_message: str = Field(..., description="Initial agent message")
    created_at: str = Field(..., description="ISO datetime")


class AssessmentMessageResponse(BaseModel):
    """Response for assessment message."""
    session_id: str = Field(..., description="Assessment session ID")
    user_message: str = Field(..., description="Echo of user's message")
    response: str = Field(..., description="Agent response")
    assessment_status: str = Field(..., description="in_progress or complete")
    profile_complete: bool = Field(..., description="Whether profile is complete")


class AssessmentProfileResponse(BaseModel):
    """Response for assessment profile."""
    session_id: str = Field(..., description="Assessment session ID")
    profile: Dict[str, Any] = Field(..., description="User profile")
    status: str = Field(..., description="Session status")
    created_at: str = Field(..., description="ISO datetime")


# Curriculum Planning Models
class CurriculumPlanRequest(BaseModel):
    """Request to create curriculum plan."""
    user_profile: Dict[str, Any] = Field(..., description="User profile from assessment")
    subject: str = Field(..., description="Subject to create curriculum for")
    learning_goals: Optional[str] = Field(None, description="Learning goals")
    time_constraints: Optional[str] = Field(None, description="Time constraints")


class CurriculumPlanResponse(BaseModel):
    """Response for curriculum plan."""
    plan_id: str = Field(..., description="Curriculum plan ID")
    curriculum: Dict[str, Any] = Field(..., description="Curriculum plan")
    status: str = Field(..., description="Plan status")
    created_at: str = Field(..., description="ISO datetime")


# Notebook Generation Models
class NotebookGenerateRequest(BaseModel):
    """Request to generate notebook."""
    plan_id: Optional[str] = Field(None, description="Curriculum plan ID (Option 1)")
    config: Optional[Dict[str, Any]] = Field(None, description="Direct notebook config (Option 2)")
    user_id: str = Field(..., description="User ID")
    options: Optional[Dict[str, Any]] = Field(
        default_factory=lambda: {
            "include_progress_tracking": True,
            "include_cross_references": True,
            "output_format": "markdown"
        },
        description="Generation options"
    )


class ProgressInfo(BaseModel):
    """Progress information for notebook generation."""
    current_step: str = Field(..., description="Current step")
    total_steps: int = Field(..., description="Total steps")
    percentage: int = Field(..., description="Completion percentage (0-100)")


class NotebookGenerateResponse(BaseModel):
    """Response for notebook generation."""
    notebook_id: str = Field(..., description="Notebook ID")
    status: str = Field(..., description="generating, complete, or error")
    progress: Optional[ProgressInfo] = Field(None, description="Generation progress")
    notebook_path: Optional[str] = Field(None, description="Path to generated notebook")
    created_at: str = Field(..., description="ISO datetime")


class NotebookDetailResponse(BaseModel):
    """Response for notebook details."""
    notebook_id: str = Field(..., description="Notebook ID")
    subject: str = Field(..., description="Subject")
    status: str = Field(..., description="Notebook status")
    progress: Optional[ProgressInfo] = Field(None, description="Generation progress")
    notebook_path: str = Field(..., description="Path to notebook")
    metadata: Dict[str, Any] = Field(..., description="Notebook metadata")
    structure: Dict[str, Any] = Field(..., description="Notebook structure")


class NotebookConfigResponse(BaseModel):
    """Response for notebook config."""
    notebook_id: str = Field(..., description="Notebook ID")
    config: Dict[str, Any] = Field(..., description="Notebook configuration")


class NotebookListItem(BaseModel):
    """Notebook list item."""
    notebook_id: str = Field(..., description="Notebook ID")
    subject: str = Field(..., description="Subject")
    status: str = Field(..., description="Status")
    created_at: str = Field(..., description="ISO datetime")
    updated_at: str = Field(..., description="ISO datetime")


class NotebookListResponse(BaseModel):
    """Response for notebook list."""
    notebooks: List[NotebookListItem] = Field(..., description="List of notebooks")
    total: int = Field(..., description="Total count")
    limit: int = Field(..., description="Limit")
    offset: int = Field(..., description="Offset")


class NotebookDeleteResponse(BaseModel):
    """Response for notebook deletion."""
    notebook_id: str = Field(..., description="Notebook ID")
    status: str = Field(..., description="deleted")
    deleted_at: str = Field(..., description="ISO datetime")


# JWT Token utilities
class JWTHandler:
    """Handles JWT token creation and validation."""
    
    @staticmethod
    def create_access_token(user_data: Dict[str, Any]) -> str:
        """Create a JWT access token."""
        now = datetime.now(timezone.utc)
        expire = now + timedelta(hours=settings.jwt_expiration_hours)
        
        payload = {
            "sub": user_data["sub"],
            "email": user_data["email"],
            "name": user_data["name"],
            "picture": user_data.get("picture"),  # Include picture in token
            "iat": now,
            "exp": expire,
            "type": "access_token"
        }
        
        return jwt.encode(payload, settings.jwt_secret_key, algorithm=settings.jwt_algorithm)
    
    @staticmethod
    def verify_token(token: str) -> TokenData:
        """Verify and decode JWT token."""
        try:
            payload = jwt.decode(
                token, 
                settings.jwt_secret_key, 
                algorithms=[settings.jwt_algorithm]
            )
            
            # Check if token is expired
            exp_timestamp = payload.get("exp")
            if exp_timestamp:
                exp_datetime = datetime.fromtimestamp(exp_timestamp, tz=timezone.utc)
                if datetime.now(timezone.utc) > exp_datetime:
                    raise HTTPException(
                        status_code=status.HTTP_401_UNAUTHORIZED,
                        detail="Token has expired"
                    )
            
            return TokenData(
                sub=payload.get("sub"),
                email=payload.get("email"),
                name=payload.get("name"),
                picture=payload.get("picture"),  # Extract picture from token
                exp=datetime.fromtimestamp(payload.get("exp"), tz=timezone.utc),
                iat=datetime.fromtimestamp(payload.get("iat"), tz=timezone.utc)
            )
            
        except jwt.ExpiredSignatureError:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="Token has expired"
            )
        except jwt.JWTError as e:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail=f"Invalid token: {str(e)}"
            )


# Google OAuth utilities
class GoogleAuthHandler:
    """Handles Google OAuth authentication."""
    
    @staticmethod
    def verify_google_token(token: str) -> Dict[str, Any]:
        """Verify Google ID token and extract user information."""
        try:
            # Verify the token with Google
            idinfo = id_token.verify_oauth2_token(
                token, 
                google_requests.Request(), 
                settings.google_client_id
            )
            
            # Verify the issuer
            if idinfo['iss'] not in ['accounts.google.com', 'https://accounts.google.com']:
                raise ValueError('Wrong issuer.')
            
            return {
                "sub": idinfo["sub"],
                "email": idinfo["email"],
                "name": idinfo["name"],
                "picture": idinfo.get("picture"),
                "email_verified": idinfo.get("email_verified", False)
            }
            
        except ValueError as e:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail=f"Invalid Google token: {str(e)}"
            )
        except Exception as e:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail=f"Token verification failed: {str(e)}"
            )


# Authentication dependencies
async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)) -> TokenData:
    """Dependency to get current authenticated user from JWT token."""
    if not credentials:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Authorization header missing"
        )
    
    token = credentials.credentials
    return JWTHandler.verify_token(token)


async def get_optional_user(request: Request) -> Optional[TokenData]:
    """Optional authentication dependency that doesn't raise errors."""
    try:
        auth_header = request.headers.get("Authorization")
        if not auth_header or not auth_header.startswith("Bearer "):
            return None
        
        token = auth_header.split(" ")[1]
        return JWTHandler.verify_token(token)
    except:
        return None


# Authentication routes
@app.post("/auth/google", response_model=LoginResponse)
async def google_login(request: GoogleTokenRequest):
    """Authenticate user with Google ID token."""
    # Verify Google token and get user info
    user_info = GoogleAuthHandler.verify_google_token(request.token)
    
    # Create JWT access token
    access_token = JWTHandler.create_access_token(user_info)
    
    return LoginResponse(
        access_token=access_token,
        token_type="bearer",
        expires_in=settings.jwt_expiration_hours * 3600,  # Convert hours to seconds
        user_info=user_info
    )


@app.post("/auth/verify")
async def verify_token(current_user: TokenData = Depends(get_current_user)):
    """Verify if the current JWT token is valid."""
    return {
        "valid": True,
        "user": {
            "sub": current_user.sub,
            "email": current_user.email,
            "name": current_user.name,
            "picture": current_user.picture,  # Include picture in response
            "exp": current_user.exp.isoformat(),
            "iat": current_user.iat.isoformat()
        }
    }


@app.post("/auth/refresh")
async def refresh_token(current_user: TokenData = Depends(get_current_user)):
    """Refresh the JWT token."""
    user_data = {
        "sub": current_user.sub,
        "email": current_user.email,
        "name": current_user.name,
        "picture": current_user.picture  # Include picture in refresh
    }
    
    new_token = JWTHandler.create_access_token(user_data)
    
    return LoginResponse(
        access_token=new_token,
        token_type="bearer",
        expires_in=settings.jwt_expiration_hours * 3600,
        user_info=user_data
    )


# Public routes
@app.get("/")
async def root():
    """Public root endpoint."""
    return {
        "message": "LearnPad API",
        "version": "1.0.0",
        "status": "running",
        "authentication": "Google OAuth + JWT"
    }


@app.get("/health")
async def health_check():
    """Public health check endpoint."""
    return {
        "status": "healthy",
        "timestamp": datetime.now(timezone.utc).isoformat(),
        "google_client_configured": bool(settings.google_client_id)
    }


# Protected routes examples
@app.get("/protected")
async def protected_route(current_user: TokenData = Depends(get_current_user)):
    """Example protected route that requires authentication."""
    return {
        "message": "This is a protected route",
        "user": {
            "sub": current_user.sub,
            "email": current_user.email,
            "name": current_user.name
        }
    }


@app.get("/profile")
async def get_profile(current_user: TokenData = Depends(get_current_user)):
    """Get current user profile."""
    return {
        "sub": current_user.sub,
        "email": current_user.email,
        "name": current_user.name,
        "token_issued_at": current_user.iat.isoformat(),
        "token_expires_at": current_user.exp.isoformat()
    }


@app.get("/optional-auth")
async def optional_auth_route(current_user: Optional[TokenData] = Depends(get_optional_user)):
    """Example route with optional authentication."""
    if current_user:
        return {
            "message": "Hello authenticated user!",
            "user": current_user.email
        }
    else:
        return {
            "message": "Hello anonymous user!",
            "note": "You can access this route without authentication"
        }


# ============================================================================
# Notebook API Implementation
# ============================================================================

# In-memory storage (in production, use Redis or database)
_assessment_sessions: Dict[str, Dict[str, Any]] = {}
_curriculum_plans: Dict[str, Dict[str, Any]] = {}
_notebooks: Dict[str, Dict[str, Any]] = {}


def _cleanup_expired_sessions():
    """Clean up expired assessment sessions."""
    now = datetime.now(timezone.utc)
    expired = []
    for session_id, session in _assessment_sessions.items():
        expires_at = session.get("expires_at")
        if expires_at and now > expires_at:
            expired.append(session_id)
    for session_id in expired:
        del _assessment_sessions[session_id]


# User Assessment APIs
@app.post("/api/notebooks/assess/start", response_model=AssessmentStartResponse)
async def start_assessment(request: AssessmentStartRequest, current_user: TokenData = Depends(get_current_user)):
    """Start a new user assessment session."""
    _cleanup_expired_sessions()
    
    session_id = str(uuid.uuid4())
    expires_at = datetime.now(timezone.utc) + timedelta(hours=settings.assessment_session_ttl_hours)
    
    # Initialize assessment conversation
    initial_prompt = "Hello! I'm here to help you create a personalized learning experience. "
    if request.subject:
        initial_prompt += f"I see you're interested in {request.subject}. "
    if request.initial_goals:
        initial_prompt += f"Your initial goals are: {request.initial_goals}. "
    initial_prompt += "Let's start by understanding your learning preferences and experience level. What's your current experience level with this subject?"
    
    try:
        if adk_client and adk_client.is_available():
            try:
                # Use ADK HTTP client to call user assessment agent
                print(f"ü§ñ Using ADK API server for assessment")
                response_text = adk_client.generate_content_simple(
                    app_name="user_assessment",
                    user_id=request.user_id,
                    message=initial_prompt,
                    initial_state={"session_id": session_id}
                )
            except Exception as adk_error:
                # ADK server error - fall back to placeholder
                print(f"‚ùå ADK server error: {adk_error}")
                print(f"‚ö†Ô∏è Falling back to placeholder response")
                response_text = (
                    "Hi! I'm here to help you create a personalized learning plan. "
                    "The AI assessment agent encountered an error, but I can still help you get started. "
                    "Please tell me about your current experience level, learning goals, and how you prefer to learn. "
                    "I'll help you create a customized curriculum based on your responses."
                )
        else:
            # Fallback to simple response if ADK not available
            print(f"‚ö†Ô∏è ADK API server not available, using fallback response")
            response_text = (
                "Hi! I'm here to help you create a personalized learning plan. "
                "The AI assessment agent is currently offline, but I can still help you get started. "
                "Please tell me about your current experience level, learning goals, and how you prefer to learn. "
                "I'll help you create a customized curriculum based on your responses."
            )
        
        _assessment_sessions[session_id] = {
            "session_id": session_id,
            "user_id": request.user_id,
            "conversation_history": [
                {"role": "assistant", "content": response_text}
            ],
            "status": "in_progress",
            "profile": None,
            "created_at": datetime.now(timezone.utc),
            "expires_at": expires_at
        }
        print(f"Assessment session started: {session_id}")
        print(f"Response text: {response_text}")
        return AssessmentStartResponse(
            session_id=session_id,
            status="started",
            initial_message=response_text,
            created_at=datetime.now(timezone.utc).isoformat()
        )
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error starting assessment: {str(e)}"
        )


@app.post("/api/notebooks/assess/{session_id}/message", response_model=AssessmentMessageResponse)
async def send_assessment_message(
    session_id: str,
    request: AssessmentMessageRequest,
    current_user: TokenData = Depends(get_current_user)
):
    """Continue assessment conversation."""
    
    _cleanup_expired_sessions()
    
    if session_id not in _assessment_sessions:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Assessment session not found"
        )
    
    session = _assessment_sessions[session_id]
    
    # Check if session expired
    if session.get("expires_at") and datetime.now(timezone.utc) > session["expires_at"]:
        del _assessment_sessions[session_id]
        raise HTTPException(
            status_code=status.HTTP_410_GONE,
            detail="Assessment session has expired"
        )
    
    # Check user ownership
    if session["user_id"] != request.user_id:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Access denied"
        )
    
    # Build conversation context
    conversation_context = "\n".join([
        f"{msg['role']}: {msg['content']}"
        for msg in session["conversation_history"]
    ])
    conversation_context += f"\nuser: {request.message}"
    
    try:
        if adk_client and adk_client.is_available():
            # Use ADK HTTP client to call user assessment agent
            print(f"ü§ñ Using ADK API server for assessment message")
            response_text = adk_client.generate_content_simple(
                app_name="user_assessment",
                user_id=request.user_id,
                message=conversation_context,
                initial_state={"session_id": session_id}
            )
        else:
            # Fallback to simple echo response
            print(f"‚ö†Ô∏è ADK API server not available, using fallback response")
            response_text = (
                f"Thank you for sharing that. I understand you said: '{request.message}'. "
                "While the AI assessment agent is offline, I'm collecting your information. "
                "Please continue to tell me about your learning goals, experience level, "
                "and preferred learning style so I can help create a customized plan for you."
            )
        
        # Update conversation history
        session["conversation_history"].append({"role": "user", "content": request.message})
        session["conversation_history"].append({"role": "assistant", "content": response_text})
        
        # Check if profile is complete (agent should call create_user_profile)
        # For demo: Mark complete after 3+ exchanges or if agent indicates completion
        message_count = len(session["conversation_history"])
        profile_complete = (
            message_count >= 6 or  # 3 user messages + 3 assistant responses = ready
            "profile complete" in response_text.lower() or 
            "ready to create" in response_text.lower() or
            session.get("profile") is not None
        )
        
        if profile_complete and session.get("profile") is None:
            # Try to extract profile from response
            # In a real implementation, the agent would call the tool and we'd capture it
            # For now, we'll mark it as complete if the agent mentions it
            pass
        
        return AssessmentMessageResponse(
            session_id=session_id,
            user_message=request.message,  # Echo back user's message
            response=response_text,
            assessment_status="complete" if profile_complete else "in_progress",
            profile_complete=profile_complete
        )
    except Exception as e:
        print(f"‚ùå Error in send_assessment_message: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error processing message: {str(e)}"
        )


@app.get("/api/notebooks/assess/{session_id}/profile", response_model=AssessmentProfileResponse)
async def get_assessment_profile(
    session_id: str,
    current_user: TokenData = Depends(get_current_user)
):
    """Get the final user profile after assessment."""
    _cleanup_expired_sessions()
    
    if session_id not in _assessment_sessions:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Assessment session not found"
        )
    
    session = _assessment_sessions[session_id]
    
    if session.get("expires_at") and datetime.now(timezone.utc) > session["expires_at"]:
        del _assessment_sessions[session_id]
        raise HTTPException(
            status_code=status.HTTP_410_GONE,
            detail="Assessment session has expired"
        )
    
    # If profile not yet extracted, try to generate it from conversation
    if session.get("profile") is None:
        # In a real implementation, we'd call the agent to generate the profile
        # For now, return a placeholder structure
        session["profile"] = {
            "experience_level": "intermediate",
            "learning_goals": "Learn the subject",
            "learning_style": {
                "visual": 0.5,
                "hands_on": 0.5,
                "theoretical": 0.5,
                "combination": True
            },
            "control_preferences": {
                "guidance_level": 0.5,
                "autonomy_level": 0.5,
                "preferred_approach": "mixed"
            },
            "time_constraints": {
                "hours_per_week": 10,
                "target_completion": "2 months",
                "pacing_preference": "moderate"
            },
            "theory_vs_practice_ratio": {
                "theory_percentage": 50,
                "practice_percentage": 50
            },
            "knowledge_gaps": [],
            "readiness_score": 0.5,
            "prerequisites_needed": []
        }
    
    return AssessmentProfileResponse(
        session_id=session_id,
        profile=session["profile"],
        status="complete",
        created_at=session["created_at"].isoformat()
    )


# Curriculum Planning APIs
@app.post("/api/notebooks/plan", response_model=CurriculumPlanResponse)
async def create_curriculum_plan(
    request: CurriculumPlanRequest,
    current_user: TokenData = Depends(get_current_user)
):
    """Create a curriculum plan from user profile and subject."""
    
    plan_id = str(uuid.uuid4())
    
    try:
        # Prepare prompt for curriculum planner
        user_profile_str = json.dumps(request.user_profile)
        prompt = f"""
        Create a comprehensive curriculum plan for the following:
        
        Subject: {request.subject}
        Learning Goals: {request.learning_goals or 'Not specified'}
        Time Constraints: {request.time_constraints or 'Not specified'}
        
        User Profile:
        {user_profile_str}
        
        Please use the generate_complete_curriculum tool to create a full curriculum plan that includes:
        - Learning path with topic sequences
        - Notebook structure
        - Content depth plan
        - Assessment plan
        - Practice progression
        """
        
        if adk_client and adk_client.is_available():
            # Use ADK HTTP client to call curriculum planner agent
            print(f"ü§ñ Using ADK API server for curriculum planning")
            response_text = adk_client.generate_content_simple(
                app_name="curriculum_planner",
                user_id=current_user.sub,
                message=prompt,
                initial_state={"subject": request.subject}
            )
        else:
            # Fallback to simple response
            print(f"‚ö†Ô∏è ADK API server not available, using fallback curriculum")
            response_text = (
                f"Basic curriculum plan for {request.subject}. "
                "For AI-powered curriculum planning, start the ADK server: cd src/agents && adk api_server --port 8000"
            )
        
        # Parse curriculum (simplified - in production, extract from tool call)
        curriculum = {
            "subject": request.subject,
            "curriculum_metadata": {
                "created_for": request.user_profile.get("experience_level", "intermediate"),
                "estimated_completion_time": request.time_constraints or "TBD",
                "total_notebooks": 1,
                "total_topics": 5
            },
            "learning_path": {
                "topics": [],
                "prerequisite_map": {},
                "learning_path_summary": response_text[:500]
            },
            "notebook_structure": {},
            "content_depth_plan": {},
            "assessment_plan": {},
            "practice_progression": {}
        }
        
        _curriculum_plans[plan_id] = {
            "plan_id": plan_id,
            "curriculum": curriculum,
            "status": "complete",
            "created_at": datetime.now(timezone.utc),
            "user_id": current_user.sub
        }
        
        return CurriculumPlanResponse(
            plan_id=plan_id,
            curriculum=curriculum,
            status="complete",
            created_at=datetime.now(timezone.utc).isoformat()
        )
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error creating curriculum plan: {str(e)}"
        )


@app.get("/api/notebooks/plan/{plan_id}", response_model=CurriculumPlanResponse)
async def get_curriculum_plan(
    plan_id: str,
    current_user: TokenData = Depends(get_current_user)
):
    """Get curriculum plan details."""
    if plan_id not in _curriculum_plans:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Curriculum plan not found"
        )
    
    plan = _curriculum_plans[plan_id]
    
    # Check ownership
    if plan.get("user_id") != current_user.sub:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Access denied"
        )
    
    return CurriculumPlanResponse(
        plan_id=plan["plan_id"],
        curriculum=plan["curriculum"],
        status=plan["status"],
        created_at=plan["created_at"].isoformat()
    )


# Notebook Generation APIs
@app.post("/api/notebooks/generate", response_model=NotebookGenerateResponse)
async def generate_notebook(
    request: NotebookGenerateRequest,
    current_user: TokenData = Depends(get_current_user)
):
    """Generate notebook from curriculum plan or config."""
    # Note: We use NotebookGeneratorWithGCS which includes ADK HTTP client support
    # No need to check for NotebookGenerator anymore
    
    notebook_id = str(uuid.uuid4())
    
    # Determine config source
    config = None
    if request.config:
        config = request.config
    elif request.plan_id:
        if request.plan_id not in _curriculum_plans:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Curriculum plan not found"
            )
        plan = _curriculum_plans[request.plan_id]
        # Convert curriculum plan to notebook config
        config = _convert_curriculum_to_config(plan["curriculum"])
    else:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Either plan_id or config must be provided"
        )
    
    # Create notebook record (all files go to GCS, no local storage)
    gcs_path = f"users/{current_user.sub}/notebooks/{notebook_id}"
    
    _notebooks[notebook_id] = {
        "notebook_id": notebook_id,
        "user_id": current_user.sub,
        "subject": config.get("subject", "Unknown"),
        "status": "generating",
        "config": config,
        "gcs_path": gcs_path,  # Changed from notebook_path
        "created_at": datetime.now(timezone.utc),
        "updated_at": datetime.now(timezone.utc),
        "progress": {
            "current_step": "Initializing",
            "total_steps": 5,
            "percentage": 0
        }
    }
    
    # Start async generation (no local path needed - all goes to GCS)
    asyncio.create_task(_generate_notebook_async(notebook_id, config, gcs_path, request.options))
    
    return NotebookGenerateResponse(
        notebook_id=notebook_id,
        status="generating",
        progress=ProgressInfo(
            current_step="Initializing",
            total_steps=5,
            percentage=0
        ),
        notebook_path=None,
        created_at=datetime.now(timezone.utc).isoformat()
    )


async def _generate_notebook_async(notebook_id: str, config: Dict[str, Any], gcs_path: str, options: Dict[str, Any]):
    """Async notebook generation task - all files go directly to GCS."""
    try:
        # Save config to temp file
        import tempfile
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
            json.dump(config, f, indent=2)
            config_file = f.name
        
        # Update progress
        _notebooks[notebook_id]["progress"] = {
            "current_step": "Creating generator",
            "total_steps": 5,
            "percentage": 20
        }
        
        # Define progress callback
        def update_progress(step: str, percentage: int):
            _notebooks[notebook_id]["progress"] = {
                "current_step": step,
                "total_steps": 5,
                "percentage": percentage
            }
            _notebooks[notebook_id]["updated_at"] = datetime.now(timezone.utc)
            print(f"üìä Progress: {percentage}% - {step}")
        
        # Create generator and generate (output_dir is only used for path calculations)
        # We use a temp dir since files won't actually be saved there
        import tempfile
        temp_output = tempfile.mkdtemp(prefix=f"notebook_{notebook_id}_")
        generator = NotebookGeneratorWithGCS(config_file, temp_output, notebook_id, progress_callback=update_progress)
        
        _notebooks[notebook_id]["progress"] = {
            "current_step": "Analyzing content structure",
            "total_steps": 5,
            "percentage": 40
        }
        
        # Generate notebook with progress updates
        # We'll update progress throughout the generation
        try:
            await generator.generate_notebook()
            
            # If we reach here, generation was successful
            _notebooks[notebook_id]["status"] = "complete"
            _notebooks[notebook_id]["progress"] = {
                "current_step": "Complete - All files uploaded to GCS",
                "total_steps": 5,
                "percentage": 100
            }
            _notebooks[notebook_id]["updated_at"] = datetime.now(timezone.utc)
            print(f"‚úÖ Notebook {notebook_id} generation complete!")
        except Exception as gen_error:
            # Handle generation errors
            print(f"‚ùå Error during notebook generation: {gen_error}")
            raise
        
        # Clean up temp files and directories
        os.unlink(config_file)
        import shutil
        if os.path.exists(temp_output):
            shutil.rmtree(temp_output)
        
    except Exception as e:
        print(f"‚ùå Notebook generation failed: {e}")
        import traceback
        traceback.print_exc()
        
        _notebooks[notebook_id]["status"] = "error"
        _notebooks[notebook_id]["error"] = str(e)
        _notebooks[notebook_id]["progress"] = {
            "current_step": f"Error: {str(e)[:100]}",
            "total_steps": 5,
            "percentage": 0
        }
        _notebooks[notebook_id]["updated_at"] = datetime.now(timezone.utc)


@app.get("/api/notebooks/{notebook_id}", response_model=NotebookDetailResponse)
async def get_notebook(
    notebook_id: str,
    current_user: TokenData = Depends(get_current_user)
):
    """Get notebook details and status."""
    if notebook_id not in _notebooks:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Notebook not found"
        )
    
    notebook = _notebooks[notebook_id]
    
    # Check ownership
    if notebook["user_id"] != current_user.sub:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Access denied"
        )
    
    # Calculate structure info
    structure = {
        "total_topics": len(notebook["config"].get("topics", [])),
        "total_files": 0,  # Would need to scan directory
        "estimated_time": "TBD"
    }
    
    return NotebookDetailResponse(
        notebook_id=notebook_id,
        subject=notebook["subject"],
        status=notebook["status"],
        progress=ProgressInfo(**notebook["progress"]) if notebook.get("progress") else None,
        notebook_path=notebook.get("gcs_path", f"users/{notebook['user_id']}/notebooks/{notebook_id}"),
        metadata={
            "created_at": notebook["created_at"].isoformat(),
            "updated_at": notebook["updated_at"].isoformat(),
            "user_id": notebook["user_id"]
        },
        structure=structure
    )


@app.get("/api/notebooks/{notebook_id}/config", response_model=NotebookConfigResponse)
async def get_notebook_config(
    notebook_id: str,
    current_user: TokenData = Depends(get_current_user)
):
    """Get the notebook configuration used for generation."""
    if notebook_id not in _notebooks:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Notebook not found"
        )
    
    notebook = _notebooks[notebook_id]
    
    # Check ownership
    if notebook["user_id"] != current_user.sub:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Access denied"
        )
    
    return NotebookConfigResponse(
        notebook_id=notebook_id,
        config=notebook["config"]
    )


# Notebook Management APIs
@app.get("/api/notebooks", response_model=NotebookListResponse)
async def list_notebooks(
    status_filter: Optional[str] = Query(None, alias="status"),
    subject_filter: Optional[str] = Query(None, alias="subject"),
    limit: int = Query(20, ge=1, le=100),
    offset: int = Query(0, ge=0),
    current_user: TokenData = Depends(get_current_user)
):
    """List all notebooks for the authenticated user."""
    # Filter by user
    user_notebooks = [
        nb for nb in _notebooks.values()
        if nb["user_id"] == current_user.sub
    ]
    
    # Apply filters
    if status_filter:
        user_notebooks = [nb for nb in user_notebooks if nb["status"] == status_filter]
    if subject_filter:
        user_notebooks = [nb for nb in user_notebooks if subject_filter.lower() in nb["subject"].lower()]
    
    # Sort by created_at (newest first)
    user_notebooks.sort(key=lambda x: x["created_at"], reverse=True)
    
    # Paginate
    total = len(user_notebooks)
    paginated = user_notebooks[offset:offset + limit]
    
    return NotebookListResponse(
        notebooks=[
            NotebookListItem(
                notebook_id=nb["notebook_id"],
                subject=nb["subject"],
                status=nb["status"],
                created_at=nb["created_at"].isoformat(),
                updated_at=nb["updated_at"].isoformat()
            )
            for nb in paginated
        ],
        total=total,
        limit=limit,
        offset=offset
    )


@app.delete("/api/notebooks/{notebook_id}", response_model=NotebookDeleteResponse)
async def delete_notebook(
    notebook_id: str,
    current_user: TokenData = Depends(get_current_user)
):
    """Delete a notebook."""
    if notebook_id not in _notebooks:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Notebook not found"
        )
    
    notebook = _notebooks[notebook_id]
    
    # Check ownership
    if notebook["user_id"] != current_user.sub:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Access denied"
        )
    
    # Delete notebook files from GCS
    try:
        gcs_path = notebook.get("gcs_path", f"users/{notebook['user_id']}/notebooks/{notebook_id}")
        # TODO: Implement GCS deletion when needed
        # For now, just remove from in-memory storage
        print(f"üì¶ Would delete GCS files at: {gcs_path}")
    except Exception as e:
        print(f"‚ö†Ô∏è Failed to delete GCS files: {e}")
    
    # Remove from storage
    del _notebooks[notebook_id]
    
    return NotebookDeleteResponse(
        notebook_id=notebook_id,
        status="deleted",
        deleted_at=datetime.now(timezone.utc).isoformat()
    )


# Helper functions
def _extract_agent_response(response) -> str:
    """Extract text response from agent response."""
    if isinstance(response, str):
        return response
    
    if isinstance(response, list):
        text_parts = []
        for event in response:
            if hasattr(event, 'content') and event.content:
                if hasattr(event.content, 'parts'):
                    for part in event.content.parts:
                        if hasattr(part, 'text') and part.text:
                            text_parts.append(part.text.strip())
        if text_parts:
            return "\n".join(text_parts)
    
    if hasattr(response, 'content') and response.content:
        if hasattr(response.content, 'parts'):
            text_parts = []
            for part in response.content.parts:
                if hasattr(part, 'text') and part.text:
                    text_parts.append(part.text.strip())
            if text_parts:
                return "\n".join(text_parts)
    
    return str(response)


def _convert_curriculum_to_config(curriculum: Dict[str, Any]) -> Dict[str, Any]:
    """Convert curriculum plan to notebook config format."""
    learning_path = curriculum.get("learning_path", {})
    topics = learning_path.get("topics", [])
    
    config = {
        "subject": curriculum.get("subject", "Unknown"),
        "description": f"Curriculum for {curriculum.get('subject', 'Unknown')}",
        "difficulty": curriculum.get("curriculum_metadata", {}).get("created_for", "intermediate"),
        "prerequisites": [],
        "content_depth": "intermediate",
        "include_progress_tracking": True,
        "include_cross_references": True,
        "output_format": "markdown",
        "topics": [
            {
                "name": topic.get("name", f"Topic {i+1}"),
                "description": topic.get("description", ""),
                "difficulty": topic.get("difficulty", "intermediate"),
                "estimated_time": topic.get("estimated_time", "2 hours"),
                "key_concepts": topic.get("key_concepts", []),
                "learning_objectives": topic.get("learning_objectives", []),
                "prerequisites": topic.get("prerequisites", []),
                "subtopics": []
            }
            for i, topic in enumerate(topics)
        ],
        "metadata": {
            "version": "1.0.0",
            "created_date": datetime.now(timezone.utc).strftime("%Y-%m-%d"),
            "tags": []
        }
    }
    
    return config

@app.get("/api/notebooks/{notebook_id}/tree")
async def get_notebook_tree(
    notebook_id: str,
    current_user: TokenData = Depends(get_current_user)
):
    """Get complete file tree structure for a notebook."""
    # Verify ownership
    # Get tree from GCS
    tree = gcs_storage.get_file_tree(current_user.sub, notebook_id)
    return {"tree": tree}

@app.get("/api/notebooks/{notebook_id}/files")
async def list_notebook_files(
    notebook_id: str,
    prefix: str = Query("", description="Directory prefix"),
    current_user: TokenData = Depends(get_current_user)
):
    """List files in a notebook directory."""
    files = gcs_storage.list_files(current_user.sub, notebook_id, prefix)
    return {"files": files}

@app.get("/api/notebooks/{notebook_id}/file")
async def get_notebook_file(
    notebook_id: str,
    file_path: str = Query(..., description="Relative file path"),
    current_user: TokenData = Depends(get_current_user)
):
    """Get file content."""
    content = gcs_storage.download_file(current_user.sub, notebook_id, file_path)
    return {"content": content, "path": file_path}

@app.get("/api/notebooks/{notebook_id}/file/url")
async def get_file_signed_url(
    notebook_id: str,
    file_path: str = Query(..., description="Relative file path"),
    current_user: TokenData = Depends(get_current_user)
):
    """Get signed URL for direct frontend access."""
    url = gcs_storage.generate_signed_url(
        current_user.sub, 
        notebook_id, 
        file_path
    )
    return {"url": url, "expires_in": 3600}


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=8001)
